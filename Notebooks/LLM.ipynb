{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bc58b96-b87b-4f64-bcbb-ce7ba70185a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import json\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acd8e2aa-b41d-4905-8fc5-3217ad1be5a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Carrega as variaveis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "api_llm = os.getenv(\"GEMINI_API_KEY\")\n",
    "DEFAULT_PATH = os.getenv(\"DEFAULT_PATH\")\n",
    "\n",
    "current_date = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b0c18d2-e705-4460-9312-d7f1f564c019",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lendo os dados da tabela silver\n",
    "df = spark.read.parquet(f\"{DEFAULT_PATH}/Silver/*.parquet\")\n",
    "\n",
    "# Transforma os dados em uma estrutura json para melhor entendimento do LLM\n",
    "dados_json = df.toPandas().to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "369d6854-5be2-4908-b1a6-1553669ec6c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt_analise = f\"\"\"\n",
    "**FUNÇÃO:** Você é um **Analista de Câmbio Sênior** com foco no Real Brasileiro (BRL). Sua tarefa é processar os dados de moedas fornecidos no formato JSON e gerar uma análise completa com insights.\n",
    "\n",
    "**DADOS DE ENTRADA (JSON):**\n",
    "[{dados_json}]\n",
    "\n",
    "**INSTRUÇÕES DE ANÁLISE:**\n",
    "\n",
    "1.  **Moedas Extremas:** Identifique as **3 moedas mais fortes** e as **3 mais fracas** em relação ao BRL (com base no valor mais alto e mais baixo da 'diferenca_brl').\n",
    "2.  **Média Continental:** Calcule a **média aritmética** da 'diferenca_brl' para cada continente listado.\n",
    "3.  **Insights:** Gere **3 insights** profissionais, claros e acionáveis, explicando o que cada um significa para um investidor brasileiro.\n",
    "\n",
    "**FORMATO DE SAÍDA OBRIGATÓRIO:**\n",
    "\n",
    "A resposta deve ser **SOMENTE** o texto da análise, formatado em **Markdown** (com títulos, listas, e **negrito**), totalmente em **Português do Brasil**. Não inclua o JSON de entrada na saída e não adicione nenhum comentário antes do início da análise.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ddf4245-ae58-485d-be1b-88205bf33798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Envia o prompt para o LLM\n",
    "try:\n",
    "    # Conexão com o LLM\n",
    "    # obs: ele localiza a api_key no arquivo .env com o nome de GEMINI_API_KEY\n",
    "    client = genai.Client()\n",
    "\n",
    "    # Envia o prompt para o LLM\n",
    "    resposta = client.models.generate_content( \n",
    "        model='gemini-2.5-flash', \n",
    "        contents=prompt_analise\n",
    "    )\n",
    "\n",
    "    resultado = resposta.text\n",
    "\n",
    "    print(\"--- Insights Gerados ---\")\n",
    "    print(resultado)\n",
    "    print(\"------------------------\")\n",
    "\n",
    "    if resultado != None:\n",
    "        try:\n",
    "            with open(f'{DEFAULT_PATH}/Gold/relatorio_llm_{current_date}.txt', 'w') as txt:\n",
    "                txt.write(resultado)\n",
    "        except Exception as erro:\n",
    "            print(f\"Não foi possível criar o arquivo de relatorio pelo seguinte erro: {erro}\")\n",
    "except Exception as erro:\n",
    "    print('Não foi possível se conectar ao LLM')\n",
    "    print(erro)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "python-dotenv",
     "google-genai"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LLM",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
